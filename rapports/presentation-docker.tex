\newcommand{\bassangPrjSemestre}{Docker and Internet of Things (travail de semestre)}
\newcommand{\bassangPrjBachelor}{Docker and Internet of Things (travail de Bachelor)}
\section{Introduction}

Le but de ce chapitre est d'apporter un contexte au projet réalisé afin de comprendre ce qui est expliqué dans la suite de ce document. Si le lecteur souhaite connaître les tréfonds de Docker, il est recommandé de lire le rapport "\bassangPrjSemestre" de M. Loic Bassang \cite{bassang_semestre}. 

Docker est un outil qui permet d'empaqueter une application et ses dépendances dans un container léger, auto-suffisant, isolé et portable. En intégrant leur application dans un container, les développeurs s'assurent que celle-ci va tourner sur n'importe quel environnement GNU/Linux. Ainsi, le temps passé à configurer les différents environnements (développement, test et production typiquement) est réduit voire même unifié\cite{shipping_container_linux_code}\cite{wikipedia_docker}\cite{what_is_docker}.

Les caractéristiques principales des containers Docker sont les suivantes :
\begin{itemize}
\item \textit{légers} : les containers partagent le même kernel et librairies que le système d'exploitation hôte permettant ainsi un démarrage rapide des containers et une utilisation mémoire contenue
\item \textit{isolés} : les containers sont isolés grâce à des mécanismes offerts par le kernel. Voir section \ref{pres-docker-isolation} pour plus de détails
\item \textit{éphémères et maintenables} : les containers sont conçus pour être créés et détruits régulièrement contrairement à un serveur ou une machine virtuelle pour lesquels un arrêt est souvent critique. Ils sont maintenables dans le sens où il est possible de revenir à une version précédente facilement et qu'il est aisé de déployer une nouvelle version
\end{itemize}

Les sections qui suivent abordent un peu plus en profondeur certains points clés de Docker qui ont été jugés importants.

\section{Containers vs machines virtuelles}
Suite à la lecture de la section précédente, il serait normal de se dire que ces containers partagent certaines caractéristiques avec les machines virtuelles.

Voici les différences majeures qu'il existe entre les containers et les machines virtuelles\cite{what_is_docker}.

\begin{figure}[hbtp]
\centering
\includegraphics[scale=0.5]{img/containers_vs_vm.png}
\caption{Containers vs machines virtuelles}
\end{figure}

Les machines virtuelles possèdent leur propre OS qui embarque ses propres binaires et librairies. Ceci engendre une perte d'espace disque importante surtout si les binaires ou libraires sont communes à plusieurs machines virtuelles. De plus, démarrer une machine virtuelle prend du temps (jusqu'à plusieurs minutes). En outre, les machines virtuelles doivent installer leurs propres drivers afin de communiquer avec l'hyperviseur (logiciel s'exécutant à l'intérieur d'un OS hôte qui gère les machines virtuelles). Un avantage cependant est l'isolation complète d'une machine virtuelle qui ne peut communiquer avec les autres par défaut.

Les containers s'exécutent de manière isolée par dessus l'OS hôte qui partage ses ressources (kernel, binaires, librairies, périphériques,...). Plus légers, les containers démarrent en quelques secondes seulement. Sur une machine, il est tout à fait possible de lancer de milliers de containers similaires car l'empreinte mémoire est réduite et l'espace disque occupé est partagé si les containers sont semblables. Ceci est expliqué plus en détails à la section \ref{pres-docker-systeme-fichiers-couches}. Les containers sont isolés mais ils peuvent aussi communiquer entre eux si on leur a explicitement donner l'autorisation.

Si le lecteur désire connaître plus de détails concernant la virtualisation, il est conseillé de lire le chapitre 3.2 du rapport "\bassangPrjSemestre" de M. Loic Bassang \cite{bassang_semestre} qui amène une bonne introduction aux différents types de virtualisation.


\section{Docker images et Docker containers}
Avec Docker, une application est encapsulée avec toutes ses dépendances et sa configuration dans une \textbf{image}. 

Pour construire cette image, on utilise un Dockerfile. Il s'agit d'un fichier qui décrit les étapes de création et de configuration nécessaires à l'obtention de l'application configurée. C'est dans ce fichier qu'on retrouve l'OS à utiliser, les dépendances à installer et toutes autres configurations utiles au bon fonctionnement de l'application à déployer. 

Typiquement un Dockerfile permettant de lancer un serveur web Nginx qui affiche un "hello world" ressemble à ceci :

\begin{bashcode}
FROM alpine  # image de départ
MAINTAINER support@tutum.co  # mainteneur du Dockerfile
RUN apk --update add nginx php-fpm && \  # installation des dépendances
    mkdir -p /var/log/nginx && \
    touch /var/log/nginx/access.log && \
    mkdir -p /tmp/nginx && \
    echo "clear_env = no" >> /etc/php/php-fpm.conf
ADD www /www  # ajout des sources de l'application
ADD nginx.conf /etc/nginx/  # ajout d'un fichier de configuration
EXPOSE 80  # ouverture du port 80
CMD php-fpm -d variables_order="EGPCS" && (tail -F /var/log/nginx/access.log &) && exec nginx -g "daemon off;" # commande à lancer au lancement du container
\end{bashcode}

Source: \url{https://github.com/tutumcloud/hello-world/blob/master/Dockerfile}

Un Dockerfile est en quelque sorte la recette de cuisine qui permet de construire une image Docker.

Une fois l'image construite, on peut exécuter l'application dans un container. Un container Docker est donc une instance de l'image fraîchement créée. La figure \ref{docker-dockerfile-image-container} montre les relations entre un Dockerfile, une image et un container.

\begin{figure}[hbtp]
\centering
\includegraphics[scale=0.7]{img/docker-dockerfile-image-container.png}
\caption{Dockerfile, image et container}
\label{docker-dockerfile-image-container}
\end{figure}


\section{Système de fichiers en couche}\label{pres-docker-systeme-fichiers-couches}
Chaque image Docker est composée d'une liste de couches (\textit{layers}) superposées en lecture seule\cite{understanding_image_container_driver_storage}. Chaque couche représente la différence du système de fichiers par rapport à la couche précédente. Sur la figure \ref{docker-image-layers}, on peut voir 4 couches (identifiables avec des ID) et leur taille respectives.

\begin{figure}[hbtp]
\centering
\includegraphics[scale=0.8]{img/image-layers}
\caption{Couches d'une image Docker}
\label{docker-image-layers}
\end{figure}

A la création d'un container, une nouvelle couche fine est ajoutée. Cette couche, appelée "container layer" est accessible en écriture durant l'exécution du container. La figure \ref{docker-container-layers} le montre clairement.

\begin{figure}[hbtp]
\centering
\includegraphics[scale=0.8]{img/container-layers}
\caption{Couches d'un container Docker}
\label{docker-container-layers}
\end{figure}

Un mot supplémentaire sur une nouvelle caractéristique arrivée avec Docker 1.10 (mars 2016); avant cette version, Docker attribuait des UUID\footnote{UUID : \url{https://fr.wikipedia.org/wiki/Universal_Unique_Identifier}} générés aléatoirement pour identifier les couches d'une image. Désormais, ces UUID sont remplacés par des hash appelés \textit{secure content hash}.

Les différences principales entre un UUID et un hash sont :
\begin{itemize}
\item Un UUID est généré aléatoirement, donc deux images exactement identiques auront un UUID différent alors qu'en utilisant un hash, le résultat sera identique
\item Avec les UUID, même si la probabilité est rare\footnote{Probabilité de doublon : \url{https://en.wikipedia.org/wiki/Universally_unique_identifier\#Random_UUID_probability_of_duplicates}}, il est possible de générer deux fois le même UUID ce qui peut poser des problèmes lors de la construction des images
\item Une image téléchargée chez une personne A aura un UUID différent que la même image téléchargée chez une personne B. Impossible de s'assurer de l'intégrité de l'image téléchargée en se basant sur l'UUID. En utilisant le hash, on s'assure du même résultat si l'image est identique
\end{itemize}

Par conséquent Docker avance les avantages suivants:
\begin{itemize}
\item Intégrité des images téléchargées et envoyées (sur Docker Hub par exemple)
\item Évite les collisions lors de l'identification des images et des couches
\item Permet de partager des couches identiques qui proviendraient de \textit{build} différents
\end{itemize}

Le dernier point est relativement intéressant. En effet, si deux images de base (Ubuntu et Debian) sont différentes mais qu'une couche supérieure est identique (par exemple l'ajout d'un même fichier texte) alors cette couche supérieure peut être partagée entre les deux images (puisqu'elle possède le même hash). Ceci peut potentiellement offrir un gain d'espace disque conséquent si plusieurs images partagent plusieurs couches identiques. Ceci n'aurait pas pu être possible avec les UUID car les deux couches auraient produit deux UUID différents. Un exemple est visible à la figure \ref{shared-layer-hash}

\begin{figure}[hbtp]
\centering
\includegraphics[scale=0.7]{img/shared-layer-hash}
\caption{Couche partagée entre deux images Docker}
\label{shared-layer-hash}
\end{figure}

D'autres explications plus détaillées sur le système de fichiers en couches ont fait l'objet du chapitre 5.4.1 du rapport "\bassangPrjSemestre" de M. Loic Bassang.


\section{Isolation}\label{pres-docker-isolation}
Docker met en avant le fait que ses containers soient isolés du système hôte. Pour ce faire, Docker utilise des mécanismes fournis par le kernel. On peut citer parmi ces mécanismes les \textit{namespaces} et \textit{cgroups}.

\subsection{Les namespaces}
Les namespaces permettent d'isoler certaines fonctionnalités d'un système d'exploitation utilisant Linux. Comme chroot permet aux processus de voir comme racine un dossier isolé du système et non pas la "vraie" racine, les namespaces isolent certains aspects du système comme les processus, les interfaces réseaux, les points de montage, etc.

Jusqu'à très récemment (docker < 1.10.0), Docker supportait les namespaces suivants\cite{docker_1_10_user_namespace}:

\begin{itemize}
\item PID namespace, chaque conteneur a ses propres id de processus
\item UTS namespace, pour avoir son propre hostname
\item IPC namespace, qui permet d'isoler les Communications Inter-Processus
\item Network namespace, chaque conteneur peux avoir sa propre interface réseau, son ip, ses règles de filtrage
\end{itemize}

Docker a désormais ajouté le support d'un nouveau namespace: user namespace. Celui-ci permet à un processus d'avoir les droits root au sein d'un namespace mais pas en dehors. Avant, Docker lançait les containers en root ce qui pouvait poser des problèmes de sécurité si un processus dans le container venait à en sortir; il se retrouverait root sur le système hôte. Avec la prise en charge de ce namespace, un container Docker a l'impression d'être root alors qu'il n'est, en réalité, qu'un utilisateur normal sur le système hôte.

\subsection{cgroups - Control Groups}
Cgroups (control groups) est une fonctionnalité du kernel pour limiter, prioriser, isoler et contrôler l'utilisation des ressources (CPU, RAM, utilisation disque, utilisation réseau,...). Pour limiter les ressources, cgroups propose de créer un groupe (profil) qui décrit les limitations à respecter. Par exemple, Si on crée un groupe appelé "groupe 1" et qu'on exige de lui qu'il n'utilise au maximum 25\% de la charge CPU et n'utilise au maximum 100 MB de RAM. Alors, il devient possible de lancer des programmes qui appartiennent à ce groupe et qui respectent les limites fixées.

Lorsqu'on utilise la commande \code{docker run} de Docker pour lancer un container, Docker peut utiliser cgroups et ainsi limiter les ressources du container\footnote{Docker - Runtime constraints on resources: \url{https://docs.docker.com/engine/reference/run/\#runtime-constraints-on-resources}}.

\section{Contraintes liées au monde de l'embarqué}
On entend par système embarqué, un système qui est/peut être léger, autonome, à puissance limitée, à stockage réduit, avec un OS minimal et souvent connecté.

Dans le monde de l'embarqué, il existe plusieurs problèmes récurrents lorsqu'on développe, déploie et maintient une application sur une cible. On peut citer les problèmes suivants :

\begin{itemize}
\item Cross-compilation souvent obligatoire
\item Aucune interface graphique
\item Installation et configuration des dépendances sur la cible
\item Mises à jour de l'application et de ses dépendances
\item Tests et journalisation (logs)
\item Limiter l'utilisation en CPU, RAM et disque
\end{itemize}

Bien que ces problèmes peuvent être aussi présents dans le cas d'un développement desktop, ils ne sont pas aussi préoccupants.

Docker peut être utile dans le cadre d'une application embarquée car il permet une maintenance plus aisée de l'application car on peut \textbf{versionner son installation et sa configuration ainsi que celle de ses dépendances}. Ceci permet de plus facilement mettre à jour une application mais également de pouvoir revenir à une version précédente. De plus, si un accès réseau est disponible, il est même possible d'administrer Docker à distance depuis un poste de développement en se connectant au \textit{deamon} Docker de la cible.

Cependant, il reste quelques freins et pré-requis pour pouvoir utiliser Docker sur une carte embarquée :

\textbf{GNU/Linux : } Il faut un système GNU/Linux et si possible une distribution qui intègre Docker dans ses packages

\textbf{Images compatibles : } Les images doivent être compatibles avec la plateforme de la cible. Les images x64 ne fonctionnent pas sur ARM. Actuellement, la majorité des images sont basées sur une image de base x64. Dans la plupart des cas, il suffit de trouver l'équivalent ARM de l'image de base. Par exemple, à la lecture d'un Dockerfile, il suffit de remplacer \code{FROM ubuntu} par \code{FROM armhf/ubuntu} pour que l'image arrive à se construire. Dans les autres cas, il faudra adapter les instructions du Dockerfile.

\textbf{Espace disque limité : } Il faut veiller à l'utilisation de l'espace disque. En effet, la plupart des images se basent sur des Ubuntu (~400 MB) ou des Debian (~300 MB) ce qui peut être trop volumineux pour un système embarqué. De plus plusieurs versions de ces images peuvent être téléchargées si les Dockerfiles le spécifient. Par exemple, \code{FROM ubuntu:14.04} pour l'image 1 et \code{FROM ubuntu:15.10} pour l'image 2. On favorisera l'utilisation d'une image de base légère, comme Alpine Linux\footnote{Alpine Linux : \url{http://www.alpinelinux.org/}}, commune à plusieurs applications ou processus tournant sur la cible. 